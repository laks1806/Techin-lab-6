{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kIIUoMvr8xPI",
        "fH-L9Sukeh5L"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Agenda\n",
        "\n",
        "- What is Large Language Model?\n",
        "- How does Large Language Models work?\n",
        "- What are the use cases of LLMs?\n",
        "- How to use LLMs effectively? (Prompt Engineering)\n",
        "- How to make LLms smarter?\n",
        "    - Give me more information (RAG)\n",
        "    - Train it more (fine-tuning)"
      ],
      "metadata": {
        "id": "ZPSPXFT-tRME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is Large Language Model?"
      ],
      "metadata": {
        "id": "ZHoQ67sgug2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The core task of the language model is next word prediction. Given a sequence of input words, the neural network predicts the probability distribution of what the next word will be.\n",
        "\n",
        "- Think of it like iPhone keyboard autocomplete\n",
        "\n",
        "- Web data (10TB) -> Training on 6k GPUs for 12 days (~$2M) -> ~140GB file\n",
        "\n",
        "- Compressing the Internet into a small file (~100x smaller)"
      ],
      "metadata": {
        "id": "zSaunicZwKot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How do Large Language Models work?"
      ],
      "metadata": {
        "id": "9Z0Eb7sAwBMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A large neural network with billions of parameters (knobs)\n",
        "- We can measure the output, and turn the knobs to optimize performance.\n",
        "- We don't fully understand how the knobs work (blockbox)\n",
        "- Give it a prompt, and it will \"dream\" the rest of the texts"
      ],
      "metadata": {
        "id": "I4CvtjDcwO9e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What are the use cases of LLMs?"
      ],
      "metadata": {
        "id": "NMa68vC00yGf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- NLP tasks\n",
        "    - Text generation\n",
        "    - Classification\n",
        "    - Summarization\n",
        "    - Name-Entity-Recognition\n",
        "    - Question-Answering\n",
        "    - Translation\n",
        "- Higher level tasks\n",
        "    - Research\n",
        "    - Assistants"
      ],
      "metadata": {
        "id": "iZdON5la01kj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why and why not LLMs"
      ],
      "metadata": {
        "id": "F7ukX_-U3JAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advantages and Disadvantages"
      ],
      "metadata": {
        "id": "o1HgJRMm3L8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advantages\n",
        "\n",
        "- Versatility\n",
        "- Ability to learn new tasks\n",
        "- Large knowledge\n",
        "- Strong performance\n",
        "\n",
        "### Disadvantages\n",
        "\n",
        "- Lack of true understanding\n",
        "- Hallucination and inconsistency\n",
        "- Bias and fairness issues\n",
        "- Lack of grounding\n",
        "- Difficulty with reasoning\n",
        "- Opaque decision-making\n",
        "- Computational cost\n",
        "- Privacy and security"
      ],
      "metadata": {
        "id": "0RsyCNgc4D6P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## When to use and not to use LLMs"
      ],
      "metadata": {
        "id": "ZD6VFLgI4IVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### When to use LLMs\n",
        "\n",
        "- Creative writing\n",
        "- NLP tasks\n",
        "    - Classification\n",
        "    - Summarization\n",
        "    - Name-Entity-Recognition\n",
        "    - Question-Answering\n",
        "    - Translation\n",
        "\n",
        "### When not to use LLMs\n",
        "\n",
        "- Math\n",
        "- Logic reasoning\n",
        "- Ground truth critical tasks"
      ],
      "metadata": {
        "id": "fADQwz0w4yzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to use LLMs effectively? (Prompt Engineering)\n",
        "\n",
        "Try all of the following prompting techniques using `OpenAI` or `Gemini` API"
      ],
      "metadata": {
        "id": "4bYSvgYP5MKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY = getpass.getpass()\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "kGnLcWyTFo9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "116dda1f-065a-41a2-9915-65f7742b83b1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-pro')"
      ],
      "metadata": {
        "id": "HtLbXTfQJJ4R"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_content(prompt):\n",
        "    response = model.generate_content(prompt)\n",
        "    print(response.text)"
      ],
      "metadata": {
        "id": "KVE86s9PJPc-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Six strategies for getting better results\n",
        "\n",
        "- Write clear instructions\n",
        "- Provide reference text\n",
        "- Split complex tasks into simpler subtasks\n",
        "- Give the model time to \"think\"\n",
        "- Use external tools\n",
        "- Test changes systematically\n",
        "\n",
        "source: [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering/strategy-write-clear-instructions)"
      ],
      "metadata": {
        "id": "hDGHQNqa6ZW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write clear instructions"
      ],
      "metadata": {
        "id": "-8ZZsDbP60FG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# More detailed prompts\n",
        "prompt1 = \"Tell me a joke\"\n",
        "\n",
        "prompt2 = \"Tell me a joke about Python. Please wirte it in a pirate like language. Include funny emojis\"\n",
        "\n",
        "gen_content(prompt1)\n",
        "print('---------------')\n",
        "gen_content(prompt2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "YfjFYH2tJ2Zn",
        "outputId": "23e6d662-df9a-48ad-9ff9-e4625c500785"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What do you call a boomerang that doesn't come back?\n",
            "\n",
            "A stick.\n",
            "---------------\n",
            "Ahoy matey!\n",
            "Why be a Python a landlubber's best matey?\n",
            "\n",
            "'Cause it can handle yer code like a parrot on a shoulder, me hearty! 🦜🏴‍☠️🐍\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask the model to adope a persona\n",
        "\n",
        "prompt = \"You are an expert in Python programming, please help me write a program to train a machine learning model to identify different languages\"\n",
        "gen_content(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "bi6GTG6OKPHu",
        "outputId": "9511b426-e7e4-47fb-a8aa-e67ada441ac9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "import pandas as pd\n",
            "from sklearn.feature_extraction.text import TfidfVectorizer\n",
            "from sklearn.linear_model import LogisticRegression\n",
            "from sklearn.model_selection import train_test_split, cross_val_score\n",
            "\n",
            "# Load the dataset\n",
            "df = pd.read_csv('language_dataset.csv')\n",
            "\n",
            "# Create a TF-IDF vectorizer\n",
            "vectorizer = TfidfVectorizer()\n",
            "X = vectorizer.fit_transform(df['text'])\n",
            "y = df['language']\n",
            "\n",
            "# Split the data into training and test sets\n",
            "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
            "\n",
            "# Train a logistic regression model\n",
            "model = LogisticRegression()\n",
            "model.fit(X_train, y_train)\n",
            "\n",
            "# Evaluate the model on the test set\n",
            "score = model.score(X_test, y_test)\n",
            "print('Accuracy: {:.2f}%'.format(score * 100))\n",
            "\n",
            "# Perform cross-validation to estimate the model's generalization ability\n",
            "scores = cross_val_score(model, X, y, cv=5)\n",
            "print('Cross-validation score: {:.2f}%'.format(np.mean(scores) * 100))\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j0NZAtgrU2xV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask the model to adope a persona\n",
        "\n",
        "prompt = \"You are an expert in Software Development, teach me SVM\"\n",
        "gen_content(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "outputId": "0081bec9-243d-4274-a14e-d05c95673634",
        "id": "N2-7ilIuU3Mt"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Support Vector Machines (SVMs)**\n",
            "\n",
            "**Introduction**\n",
            "\n",
            "SVMs are supervised machine learning algorithms used for classification and regression tasks. They aim to find the optimal separating hyperplane that maximizes the margin between different classes of data.\n",
            "\n",
            "**Key Concepts**\n",
            "\n",
            "* **Kernel:** A function that transforms the input data into a higher-dimensional space, where the data points become linearly separable. Common kernels include linear, polynomial, and Gaussian radial basis function (RBF).\n",
            "* **Margin:** The distance between the separating hyperplane and the closest data points of each class.\n",
            "* **Support Vectors:** The data points that define the margin and lie closest to the separating hyperplane.\n",
            "\n",
            "**Types of SVMs**\n",
            "\n",
            "* **Linear SVM:** Uses a linear kernel and is suitable for data that is linearly separable.\n",
            "* **Nonlinear SVM:** Uses a nonlinear kernel to map data into a higher-dimensional space, allowing for the classification of non-linearly separable data.\n",
            "\n",
            "**Algorithm**\n",
            "\n",
            "SVMs work by finding the hyperplane that maximizes the margin between classes. This is done by solving a constrained optimization problem:\n",
            "\n",
            "```\n",
            "minimize ||w||^2\n",
            "subject to: y_i (w^T x_i + b) >= 1 for all i\n",
            "```\n",
            "\n",
            "where:\n",
            "\n",
            "* w is the weight vector that defines the hyperplane\n",
            "* b is the bias term\n",
            "* y_i is the class label of the i-th data point\n",
            "* x_i is the i-th data point\n",
            "\n",
            "**Advantages of SVMs**\n",
            "\n",
            "* Effective for high-dimensional data\n",
            "* Robust to overfitting\n",
            "* Can handle non-linear data by using a nonlinear kernel\n",
            "* Can be used for both classification and regression\n",
            "\n",
            "**Disadvantages of SVMs**\n",
            "\n",
            "* Can be computationally expensive for large datasets\n",
            "* Sensitive to the choice of kernel and its parameters\n",
            "* May not perform well on datasets with large amounts of noise\n",
            "\n",
            "**Applications**\n",
            "\n",
            "SVMs are widely used in:\n",
            "\n",
            "* Image classification\n",
            "* Text classification\n",
            "* Natural language processing\n",
            "* Biomedicine\n",
            "* Financial forecasting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use delimiters to clearly indicate the distinct parts of the input\n",
        "\n",
        "prompt = \"\"\"You are an expert in technical recruiting. Please read the following resume and job description. Give me suggestion on how to improve my resume\n",
        "\n",
        "<job description>\n",
        "Amazon\n",
        "Senior software engineering\n",
        "The candidate should.....\n",
        "\n",
        "</job description>\n",
        "<resume>\n",
        "Ian Chen\n",
        "Software Engineer\n",
        "</resume>\n",
        "\"\"\"\n",
        "gen_content(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "bWJki2J5KgeL",
        "outputId": "5efa8fca-3cd7-4727-96a8-b27ac54dec20"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Suggested Improvements to Enhance Resume for Amazon Senior Software Engineering Position:**\n",
            "\n",
            "* **Highlight Quantifiable Accomplishments:**\n",
            "   - Use specific metrics and data to quantify your contributions in previous roles. For example, instead of stating \"Led software development projects,\" specify \"Managed a team of 10 engineers and delivered 3 major software releases, resulting in a 20% increase in user engagement.\"\n",
            "\n",
            "* **Tailor to the Job Description:**\n",
            "   - Carefully review the job description and identify the key skills and experiences required. Ensure your resume clearly demonstrates how your qualifications align with these requirements. For instance, if the description mentions expertise in Amazon Web Services (AWS), highlight any relevant projects or certifications.\n",
            "\n",
            "* **Emphasize Relevant Skills:**\n",
            "   - List your technical skills prominently and ensure they match the skills specified in the job description. Use industry-standard terminology and provide specific examples of your proficiency. Instead of simply stating \"Proficient in Java,\" specify \"Expert in Java with 5+ years of experience developing enterprise-scale applications.\"\n",
            "\n",
            "* **Incorporate Keywords:**\n",
            "   - Use keywords from the job description throughout your resume. These keywords will help your resume stand out in applicant tracking systems (ATS) and be noticed by recruiters.\n",
            "\n",
            "* **Expand Experience Section:**\n",
            "   - Provide a more detailed description of your work experience. Include responsibilities, accomplishments, and the impact of your work. Use action verbs to highlight your contributions.\n",
            "\n",
            "* **Quantify Education:**\n",
            "   - If your education is relevant to the position, provide quantifiable data to demonstrate its value. For example, instead of stating \"Master's Degree in Computer Science,\" specify \"Master's Degree in Computer Science with a 3.9 GPA and Dean's List honors.\"\n",
            "\n",
            "* **Proofread Carefully:**\n",
            "   - Take the time to proofread your resume carefully for any grammatical errors, typos, or formatting issues. A polished and error-free resume will make a positive impression on potential employers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Include details in your query to get more relevant answers\n",
        "\n",
        "```\n",
        "Summarize the meeting notes.\n",
        "```\n",
        "\n",
        "```\n",
        "Summarize the meeting notes in a single paragraph. Then write a markdown list of the speakers and each of their key points. Finally, list the next steps or action items suggested by the speakers, if any.\n",
        "```\n",
        "\n",
        "#### Ask the model to adopt a persona\n",
        "\n",
        "```\n",
        "You are an expert in Python programming. You have 20 years of programming experience.\n",
        "```\n",
        "\n",
        "#### Use delimiters to clearly indicate distinct parts of the input\n",
        "\n",
        "```\n",
        "Summarize the text delimited by triple quotes with a haiku.\n",
        "\n",
        "\"\"\"insert text here\"\"\"\n",
        "```\n",
        "\n",
        "```\n",
        "You will be provided with a pair of articles (delimited with XML tags) about the same topic. First summarize the arguments of each article. Then indicate which of them makes a better argument and explain why.\n",
        "\n",
        "<article> insert first article here </article>\n",
        "\n",
        "<article> insert second article here </article>\n",
        "```\n",
        "\n",
        "```\n",
        "You will be provided with a thesis abstract and a suggested title for it. The thesis title should give the reader a good idea of the topic of the thesis but should also be eye-catching. If the title does not meet these criteria, suggest 5 alternatives.\n",
        "\n",
        "Abstract: insert abstract here\n",
        "\n",
        "Title: insert title here\n",
        "```\n",
        "\n",
        "#### Specify the steps required to complete a task\n",
        "Some tasks are best specified as a sequence of steps. Writing the steps out explicitly can make it easier for the model to follow them.\n",
        "\n",
        "```\n",
        "Use the following step-by-step instructions to respond to user inputs.\n",
        "\n",
        "Step 1 - The user will provide you with text in triple quotes. Summarize this text in one sentence with a prefix that says \"Summary: \".\n",
        "\n",
        "Step 2 - Translate the summary from Step 1 into Spanish, with a prefix that says \"Translation: \".\n",
        "\n",
        "\"\"\"insert text here\"\"\"\n",
        "```"
      ],
      "metadata": {
        "id": "jx8mUfWYeAyR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EUXai9MwFnP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Provide Reference Text\n",
        "\n"
      ],
      "metadata": {
        "id": "kIIUoMvr8xPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Use the provided articles delimited by triple quotes to answer questions. If the answer cannot be found in the articles, write \"I could not find an answer.\"\n",
        "\n",
        "<insert articles, each delimited by triple quotes>\n",
        "\n",
        "Question: <insert question here>\n",
        "```\n",
        "\n",
        "#### Answer with citations from a reference text\n",
        "\n",
        "If the input has been supplemented with relevant knowledge, it's straightforward to request that the model add citations to its answers by referencing passages from provided documents. Note that citations in the output can then be verified programmatically by string matching within the provided documents.\n",
        "\n",
        "```\n",
        "You will be provided with a document delimited by triple quotes and a question. Your task is to answer the question using only the provided document and to cite the passage(s) of the document used to answer the question. If the document does not contain the information needed to answer this question then simply write: \"Insufficient information.\" If an answer to the question is provided, it must be annotated with a citation. Use the following format for to cite relevant passages ({\"citation\": …}).\n",
        "\n",
        "\"\"\"<insert document here>\"\"\"\n",
        "\n",
        "Question: <insert question here>\n",
        "```"
      ],
      "metadata": {
        "id": "e7iX2DvQedCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split complex tasks into simpler subtasks"
      ],
      "metadata": {
        "id": "fH-L9Sukeh5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Multi-step prompting\n",
        "\n",
        "1. Write a prompt to ask the model to classify the users input\n",
        "1. Based on the ansewr from the model, choose a second prompt to complete the task\n",
        "\n",
        "Example: Customer service chatbot\n",
        "\n",
        "```\n",
        "You are a complaint categorizer. Based on the users input and the following criteria, please output the category of the users inquery.\n",
        "```\n",
        "\n",
        "A: troubleshooting\n",
        "\n",
        "```\n",
        "You are a customer service agent. Please provide helpful instruction to help the user troubleshoot the product.\n",
        "```"
      ],
      "metadata": {
        "id": "eMp_60TTeuAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Summarization\n",
        "\n",
        "**Summarize conversations that's too long**\n",
        "\n",
        "LLMs have limited context window lengths. For long conversations that requires context preservation, consider summarize the previous conversation and start new conversation. (GPT-4 16k or 32k)\n",
        "\n",
        "**Chunk long texts then summarize recursively**\n",
        "\n",
        "Chunk longs texts (a book) into reasonably sized tokens (1024, 2048, 4906 tokens, experiemnt with them) then summarize recusively to produce summary of summaries.\n",
        "\n",
        "You can consider running (refine) strategy for summarization"
      ],
      "metadata": {
        "id": "CMi_c4l3fqhE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Give model time to think"
      ],
      "metadata": {
        "id": "iBXxrDzzhGMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Read the following JD and resume, do the following tasks\n",
        "1. Output \"good fit\" or \"not good fit\"\n",
        "2. Give the strengh and weaknesses of the candidate for this job\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Read the following JD and resume, do the following tasks\n",
        "1. Give the strengh and weaknesses of the candidate for this job\n",
        "2. Output \"good fit\" or \"not good fit\"\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dNtIiQP1AbHq",
        "outputId": "c9ff7f59-0620-4bca-90de-d30ddf632b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nRead the following JD and resume, do the following tasks\\n1. Give the strengh and weaknesses of the candidate for this job\\n2. Output \"good fit\" or \"not good fit\"\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chain of thought**\n",
        "\n",
        "The order of output matters.\n",
        "\n",
        "Ask the model to think and layout the strategy first before outputting the final decision.\n",
        "\n",
        "**Inner monologue to hide chain of thoughts**\n",
        "\n",
        "Ask the model to output the intermediate thoughts in a structured format (such as \"\"\" triple quotes) that's easy to parsed in a post procesisng step.\n",
        "\n",
        "**multi step prompting**\n",
        "\n",
        "In a evaluation or reasoning task\n",
        "\n",
        "- Ask the model to perform task on it's own\n",
        "- Evaluate the users input\n",
        "- (Bonus) Ask a different persona to give final verdict"
      ],
      "metadata": {
        "id": "CSK-_Xj2hIaL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### User External Tools"
      ],
      "metadata": {
        "id": "L07wK_6-iMZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Search for relevent information and inject into context**\n",
        "\n",
        "- Vector searching using embeddings\n",
        "- Google search\n",
        "\n",
        "**Ask model to generate code**\n",
        "\n",
        "```\n",
        "You can write and execute Python code by enclosing it in triple backticks, e.g. ```code goes here```. Use this to perform calculations.\n",
        "\n",
        "Find all real-valued roots of the following polynomial: 3*x**5 - 5*x**4 - 3*x**3 - 7*x - 10.\n",
        "```\n",
        "\n",
        "```\n",
        "You can write and execute Python code by enclosing it in triple backticks. Also note that you have access to the following module to help users send messages to their friends:\n",
        "\n",
        "```python\n",
        "import message\n",
        "message.write(to=\"John\", message=\"Hey, want to meetup after work?\")```\n",
        "```\n",
        "\n",
        "It's dangerous to run model generated code without sandboxing.\n",
        "\n",
        "Consider using [function calling](https://platform.openai.com/docs/guides/function-calling) instead"
      ],
      "metadata": {
        "id": "Xf9n2ZeiiOwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "def get_weather(location_name):\n",
        "    weather = requests.get(location_name)\n",
        "    return weather\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "You have access to this function, here is the function definition\n",
        "\n",
        "{\n",
        "    \"function_name\": \"get_weather\",\n",
        "    \"arguments: [\n",
        "        \"location_name\": \"this is the name of the location to search for the weather\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "Questions: What is the weather in Seattle?\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "get_weather(\"Seattle\")\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ShI_lWD3DINW",
        "outputId": "186bbb16-48ea-4752-e8c0-186105abb2b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nget_weather(\"Seattle\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "## Documents\n",
        "\n",
        "- [Steven Wolfram's intro to LLM](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)\n",
        "- [Mistral AI docs](https://docs.mistral.ai/guides/resources/)\n",
        "- [OpenAI Prompt Engineering](https://platform.openai.com/examples)\n",
        "- [Elastic's intro to LLM](https://www.elastic.co/what-is/large-language-models)\n",
        "\n",
        "## Youtube\n",
        "\n",
        "- [Awesome talk by Andrej Karpathy](https://youtu.be/zjkBMFhNj_g?si=wPxLgMJ2D-CZsQvv)\n",
        "- [Large Language Models](https://www.youtube.com/watch?v=YDiSFS-yHwk)\n",
        "\n",
        "## Colab Notebooks\n",
        "\n",
        "- https://colab.research.google.com/drive/1uQABWrbU17DwLQdDZ8k5d_UJVlrAkwZ5?usp=sharing\n",
        "\n",
        "## GitHub\n",
        "\n",
        "- https://github.com/mlabonne/llm-course\n",
        "\n",
        "- https://github.com/datainsightat/introduction_llm\n",
        "\n",
        "- https://github.com/Ryota-Kawamura/Generative-AI-with-LLMs/tree/main\n",
        "\n",
        "- https://github.com/sinanuozdemir/oreilly-hands-on-transformers\n",
        "\n",
        "- https://github.com/gkamradt/langchain-tutorials\n",
        "\n",
        "- https://github.com/openai/openai-cookbook\n",
        "\n",
        "- https://github.com/dair-ai/Prompt-Engineering-Guide\n",
        "\n",
        "- https://github.com/ksm26/chatGPT-Prompt-Engineering-for-Developers\n",
        "\n",
        "- https://github.com/kevinamiri/Instructgpt-prompts\n",
        "\n",
        "- https://github.com/promptslab/Promptify\n",
        "\n",
        "- https://github.com/dair-ai/Prompt-Engineering-Guide\n",
        "\n",
        "## Papers\n",
        "\n",
        "- [Attention is all you need](https://arxiv.org/abs/1706.03762)\n",
        "- [FINETUNED LANGUAGE MODELS ARE ZERO-SHOT LEARNERS](https://openreview.net/pdf?id=gEZrGCozdqR)\n",
        "- [Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165)"
      ],
      "metadata": {
        "id": "RA64OmGW6LEL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eHpT2dBBj0Zl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}